=> creating model
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
FLOPs = 4.312462336G
Params = 58.187064M
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
Epoch: [0] Lr_rate [0.01][  0/630]	Time  0.910 ( 0.910)	Loss 3.2736e+01 (3.2736e+01)	Acc@1   0.00 (  0.00)
Epoch: [0] Lr_rate [0.01][ 10/630]	Time  0.247 ( 0.311)	Loss 3.8935e+01 (3.5622e+01)	Acc@1   0.00 (  0.57)
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
FLOPs = 4.312462336G
Params = 58.187064M
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
Epoch: [0] Lr_rate [0.01][  0/630]	Time  1.329 ( 1.329)	Loss 3.1705e+01 (3.1705e+01)	Acc@1   0.00 (  0.00)
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (st_encoder): STEncoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (t_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (st_encoder): STEncoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (t_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (st_encoder): STEncoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (t_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (st_encoder): STEncoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (t_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (st_encoder): STEncoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (t_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (st_encoder): STEncoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (t_encoder): Transformer_block(
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
FLOPs = 4.177687552G
Params = 49.79948M
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
FLOPs = 4.312462336G
Params = 58.187064M
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
Epoch: [0] Lr_rate [0.01][  0/630]	Time  1.264 ( 1.264)	Loss 2.9892e+01 (2.9892e+01)	Acc@1   0.00 (  0.00)
=> creating model
 moco parameters 2048 0.999 0.2
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder1): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (shared_encoder2): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1536, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1536, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1536, out_features=1536, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1536, out_features=1536, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (shared_encoder3): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder1): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (shared_encoder2): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1536, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1536, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1536, out_features=1536, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1536, out_features=1536, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (shared_encoder3): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder1): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (shared_encoder2): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (shared_encoder3): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder1): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (shared_encoder2): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
      (shared_encoder3): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
FLOPs = 4.207604736G
Params = 62.402872M
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
Epoch: [0] Lr_rate [0.01][  0/630]	Time  1.312 ( 1.312)	Loss 3.3013e+01 (3.3013e+01)	Acc@1   0.00 (  0.00)
Epoch: [0] Lr_rate [0.01][ 10/630]	Time  0.245 ( 0.345)	Loss 3.8955e+01 (3.5433e+01)	Acc@1   0.00 (  0.71)
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
FLOPs = 4.207604736G
Params = 37.196088M
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
Epoch: [0] Lr_rate [0.01][  0/630]	Time  1.278 ( 1.278)	Loss 3.1000e+01 (3.1000e+01)	Acc@1   0.00 (  0.00)
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
FLOPs = 4.312462336G
Params = 58.187064M
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
Epoch: [0] Lr_rate [0.01][  0/630]	Time  1.251 ( 1.251)	Loss 3.0995e+01 (3.0995e+01)	Acc@1   0.00 (  0.00)
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
Number of parameter: 58.20M
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
FLOPs = 4.312462336G
Params = 58.187064M
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
Epoch: [0] Lr_rate [0.01][  0/630]	Time  1.301 ( 1.301)	Loss 2.9968e+01 (2.9968e+01)	Acc@1   0.00 (  0.00)
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
Epoch: [0] Lr_rate [0.01][  0/630]	Time  2.905 ( 2.905)	Loss 3.0975e+01 (3.0975e+01)	Acc@1   0.00 (  0.00)
Epoch: [0] Lr_rate [0.01][ 10/630]	Time  0.246 ( 0.493)	Loss 3.8970e+01 (3.5056e+01)	Acc@1   0.00 (  1.28)
=> creating model
 moco parameters 2048 0.999 0.2
weights initialization finished!
weights initialization finished!
options {'data_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_data_joint.npy', 'num_frame_path': '/home/chenhan/F-Net/data/NTU-RGB-D-60-AGCN/xsub/train_num_frame.npy', 'l_ratio': [0.1, 1], 'input_size': 64, 'input_representation': 'joint'}
STDA_Net(
  (encoder_q): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
  (encoder_k): PretrainingEncoder(
    (stda_encoder): STDA_Encoder(
      (gcn): Model(
        (data_bn): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (l1): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
        )
        (l2): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (l3): TCN_GCN_unit(
          (gcn1): unit_gcn(
            (convs): ModuleList(
              (0): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (1): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
              (2): CTRGC(
                (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
                (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
                (tanh): Tanh()
              )
            )
            (down): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (soft): Softmax(dim=-2)
            (relu): ReLU(inplace=True)
          )
          (tcn1): MultiScale_TemporalConv(
            (branches): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): TemporalConv(
                  (conv): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(4, 0), dilation=(2, 1))
                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)
                (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): Sequential(
                (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (relu): ReLU(inplace=True)
          (residual): unit_tcn(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (t_embedding): Sequential(
        (0): Linear(in_features=3200, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (s_embedding): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (fusion): Fusion(
        (maxpooling): AdaptiveMaxPool1d(output_size=1)
      )
      (shared_encoder): Transformer_block(
        (attn_t): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_s): Attention(
          (qkv): Linear(in_features=1024, out_features=4608, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1536, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (attn_g): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=1024, bias=True)
          (act): ReLU()
          (fc2): Linear(in_features=1024, out_features=1024, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
    (s_proj): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=128, bias=True)
    )
  )
)
(40320, 3, 300, 25, 2) 40320
l_ratio [0.1, 1]
torch.Size([64, 1, 1024])
torch.Size([64, 1, 1024])
Epoch: [0] Lr_rate [0.01][  0/630]	Time  2.913 ( 2.913)	Loss 3.1247e+01 (3.1247e+01)	Acc@1   0.00 (  0.00)
